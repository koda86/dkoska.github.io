---
title: "Daniel Koska"
subtitle: "Data; Science; Biomechanics"
---

## Welcome

This is intended to be a collection of ongoing and past projects, papers, coding adventures and whatever else seems worth sharing. This blog's running on GitHub Pages and is written using Quarto, (hopefully) making it easy to share code examples. And hey, if you spot something cool, you can dive straight into the GitHub repo and start playing around with it.

## Software contributions

### Functional Bootstrapped Bands

The whole journey began when I started thinking about ways to adequately characterize differences between joint angles calculated from different measurement systems. In my case, I wanted to compare joint angles from a 3D camera system and an inertial measurement unit system. In terms of choosing appropriate statistics, there are some good reads about what **not** to do and how to implement methods for **discrete** data. See, e. g., the highly cited work by Bland and Altman (e.g the papers form 1986, or 2007), who introduced the so called Limits of Agreement (LoA) approach. There's much less literature, however, on how to handle continuous differences between two measurement systems.

One paper that caught my attention is the article by [Røslien et al., (2012)](https://doi.org/10.1016/j.gaitpost.2012.05.001), which describes a way to expand the LoA method to continuous data by using a functional approach. The paper in a nutshell: Continuous data (aka curves) are approximated using functions to calculate a functional counterpart of the LoA. The problem, however, is that the approach described in the paper is not entirely functional. Rather, the actual calculation of the Functional Limits of Agreement is carried out for each individual point of the previously determined functional curves (for details see the implementation in the utilized R package *fda* by James Ramsay). Strictly speaking, this turns the whole idea of using functions on its head and results in functional LoA (or more generally: statistical bands) that are likely too narrow ([Koska et al., 2023](https://doi.org/10.1016/j.jbiomech.2023.111506)). Applied to my original problem of describing continuous differences between measurement systems, this would mean that the random measurement error is likely underestimated.

Another paper that describes a functional approach is the one by [Lenhoff et al. (1999)](https://doi.org/10.1016/S0966-6362(98)00043-5), i.e., curves/time series are approximated using functions just like in Røislien et al. (2012). The paper is not specifically about quantifying differences between measurement systems, but more generally about the construction of statistical bands (more precisely confidence and prediction bands) for biomechanical curve data. The actual hack here is that the distribution of curves is estimated by bootstrapping the coefficients of the curve functions. This means that bands are no longer calculated pointwise, but the entire curve is included in the calculation. The method in Lenhoff et al., to the best of my knowledge, is based on the work of Olshen, Biden, Wyatt, and Sutherland from the 1980s (see, for example, Sutherland et al., 1988; Olshen et al., 1989).

-   Sutherland, D., Olshen, R., Biden, E., Wyatt, M., 1988. Development of Mature Walking. Mac Keith Press. Olshen, R.A., Biden, E.N., Wyatt, M.P., Sutherland, D.H., 1989. Gait analysis and the bootstrap. Ann. Statist. 17 (4), <http://dx.doi.org/10.1214/aos/1176347372>.

-   Olshen, R.A., Biden, E.N., Wyatt, M.P., Sutherland, D.H., 1989. Gait analysis and the bootstrap. Ann. Statist. 17 (4), <http://dx.doi.org/10.1214/aos/1176347372>.

As you can see, the method is not exactly new. I was all the more surprised that I wasn't able to find a coded version of the algorithm online. This forced me to implement the algorithm from scratch, which I did using R and the formulas in the appendix of Lenhoff et al. (1999). Extremely helpful at this point was the Matlab code that a former colleague at our institute, Dr. Doris Oriwol, kindly provided me with. Her code allowed me to cross-check my implementation and correct a couple of mistakes. For instance - if I remember correctly - I struggled to implement the correction facor that adjusts the width of the bands to the desired confidence level. Not sure if I'd gotten it right without Doris' help. So, full credit to Doris!

> *As a side note: I am very grateful for people who have the know-how and the time to review the code. The description in the Lenhoff paper is rather brief, and we were not always 100% sure whether we had correctly implemented the algorithm. Further opinions and possible corrections are very welcome.*

I'm sure other researchers have been here before and would have loved to read a coded version of the algorithm. My hope is that sharing our code is a major pain release in that regard and will lead to more people adopting the method. As indicated by Lenhoff et al., functional statistical bands are not limited to the description of differences between measurement systems, but are useful wherever the variation of curve data needs to be analyzed statistically. This includes a ton of important tasks such as estimating population parameters, indicating precision, assessing statistical significance, comparing groups, forecasting future observations, quantifying uncertainty in predictions etc..

------------------------------------------------------------------------

In the course of implementing the method, I noticed something else: The examined bootstrap methods (including that of Røislien) have implemented a naive bootstrap, meaning they assume independence of the curves in the dataset. Accordingly, the papers suggested to include only one curve per subject in the bootstrap. From a methodological point of view, this is somewhat problematic since it ignores the intraindividual variance component. In the context of investigating measurement errors, for instance, this means that the variance across repeated measurements within a person is not taken into account. This may further aggravate the problem of bands being too narrow.

We therefore extended the functional bootstrap bands to include a possibility to account for repeated measurements (i.e., dependent curves). This was realized using the two-stage or double bootstrap described in [Davison and Hinkley (1997)](https://doi.org/10.1017/CBO9780511802843), in which subjects (including all of their curves) are sampled with replacement in the first stage, and one curve per subject is drawn without replacement in the second stage. In addition to sharing our code, this implementation of the two-stage bootstrap is - IMHO - the main contribution of 'our' FunBootBand method. A systematic comparison of the method with other methodological approaches for characterizing continuous differences between two measurement systemes (pointwise LoA, Functional LoA, Functional Bootstrapped bands) can be found in in [Koska et al. (2023)](https://doi.org/10.1016/j.jbiomech.2023.111506). Here, we analyzed the coverage probabilites of these models in different error scenarios (simulated and real-world data) and found that the FunBootBands showed superior performance.

------------------------------------------------------------------------

What follows are various versions of the functional bootstrap bands (ongoing development) in different programming languages. The R code has already been published as a (devtools) package, and I plan to add it to CRAN at some point as well. In addition, I'm currently porting the code to Python. If time permits and I can delve into Julia, this may be next in line. Besides porting the function to different languages to improve the accessibility, my main goal is to increase code efficiency and reduce computation times - after all, bootstrapping is quite a computationally intensive. In R this may be done using RCpp, a C++ version. In Python, there is Cython, which should significantly reduce execution time.

#### R version

The [FunBootBand](https://koda86.github.io/FunBootBand/) package contains a function to generate statistical (prediction or confidence) bands from curve data using a functional approach and bootstrapping.

```{r echo=FALSE}
# devtools::install_github("koda86/FunBootBand")
library(FunBootBand)

prediction.band <- band(data,
                        type = "prediction",
                        B = 5,
                        alpha = 0.05,
                        iid = TRUE)

plot(data[, 1], type = "l", ylim = c(-3, 3), ylab = "Amplitude")
apply(data, 2, function(x) lines(x)) |> invisible()
apply(prediction.band, 1, function(x) lines(x, col = "red", lwd = 4)) |> invisible()
```

The development version of FunBootBand can be installed from GitHub with:

devtools::install_github("koda86/FunBootBand")

#### Python version

Work in progress, see here: \[FunBoot\]

#### RCpp version

On my TODO list.

### Effort to compress (R code)

While trying out different complexity measures, I stumbled upon the 'effort to compress' (ETC) method introduced in (Nagaraj et al., 2013). ETC is a complexity measure for which code was originally presented as Matlab and Python Code. This repository contains an R implementation of the algorithm.

[effort2compress](https://github.com/koda86/effort2compress) (GitHub)

See also the website of Nithin Nagaraj for the Matlab and Python versions: [Website Nagaraj](https://sites.google.com/site/nithinnagaraj2/journal/software-toolbox-for-etc-measure)

Python implementation: [Github](https://github.com/pranaysy/ETCPy)

<!-- ## 3D joint angle calculations in Matlab -->

<!-- Matlab Code TH -->

<!-- ## Webscraping -->

<!-- ### OpenLigaDB-Api -->

<!-- ## Blog -->

<!-- ### Benchmarking classification algorithms -->

<!-- ### SPM project -->
